{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Detector from picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script detect objects from a picture. By default script is set for a 1280 x 1024 image.\n",
    "ML model is yolo4.  It was trained with 320x320 images to detect the following objects:\n",
    "\n",
    " ['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "When image is shown there will be in the window as buttons as objects we have pre-selected in the code to be identified. When the button is active the bouding borders are draw in the image, otherwise the object is not bounding bordered.\n",
    "\n",
    "The image showing stops when the ESC key is pressed. \n",
    "\n",
    "The output image is saved into \"/image_output\" folder and names \"image_output.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tkinter import Tk     # from tkinter import Tk for Python 3.x\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from gui_buttons import Buttons\n",
    "from numpy import append\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a button for classes to be detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = Buttons()\n",
    "button.add_button(\"person\",5,5)\n",
    "button.add_button(\"car\",5,25)\n",
    "button.add_button(\"cell phone\",5,45)\n",
    "button.add_button(\"bicycle\",5,65)\n",
    "button.add_button(\"sports ball\",5,85)\n",
    "\n",
    "colors = button.colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('dnn_model\\yolov4-tiny.weights','dnn_model\\yolov4-tiny.cfg')\n",
    "model = cv2.dnn_DetectionModel(net)\n",
    "size = (320,320)\n",
    "model.setInputParams(size=size, scale=1/255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definition for mouse clicks on buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_button(event, x,y,flags,params):\n",
    "    global button_object\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        button.button_click(x,y)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window creation to be selected to the mouse callback mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('Frame')\n",
    "cv2.setMouseCallback('Frame',click_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the classes file and generate a numpy array with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[]\n",
    "with open('dnn_model\\classes.txt','r') as file_object:\n",
    "    for class_name in file_object.readlines():\n",
    "        class_name = class_name.strip()\n",
    "        classes.append(class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Tk().withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "img = askopenfilename() # show an \"Open\" dialog box and return the path to the selected file\n",
    "src = cv2.imread(img, cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize to a convinient image size (the larger the size, the better the detection and worst time processing lap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percent by which the image is resized\n",
    "scale_percent = size[0]/src.shape[0]\n",
    "\n",
    "# dsize\n",
    "dsize = ( int(src.shape[1]*scale_percent), size[0])\n",
    "\n",
    "# resize image\n",
    "frame = cv2.resize(src, dsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the resized image and run the model to predict. Draw the bounding borders and classes for objects according selected buttons. Shows the image with bboxes, until a key is pressed, then save the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "while True:\n",
    "    frame = cv2.resize(src, dsize)\n",
    "\n",
    "    active_buttons=button.active_buttons_list()\n",
    "\n",
    "    (class_ids, scores, bboxes) = model.detect(frame,confThreshold=0.3, nmsThreshold=0.4)\n",
    "\n",
    "    for class_id, score, bbox in zip(class_ids, scores, bboxes):\n",
    "        (x, y, w , h) = bbox\n",
    "        class_name = classes[class_id]\n",
    "        color = colors[class_id]\n",
    "\n",
    "        if class_name in active_buttons:\n",
    "            cv2.putText(frame,str(class_name), (x,y-10), cv2.FONT_HERSHEY_PLAIN,2, color,2 )\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),color,3)\n",
    "\n",
    "    \n",
    "    button.display_buttons(frame)\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    \n",
    "    key =  cv2.waitKey(1)\n",
    "    if key == 27    :\n",
    "        break\n",
    "\n",
    "cv2.imwrite(\"//image_output//image_output.png\",frame)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c74bc13b5b42c74589485fdf151d6d754a3100e535281c45eb78a57c1ac59eed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
